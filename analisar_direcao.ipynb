{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf7a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "print(\"Bibliotecas importadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c148120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Célula 2.1: Visualização Comparativa Acelerômetro\n",
    "caminho_suave = 'data/suave/suave_1.csv'\n",
    "caminho_normal = 'data/normal/normal_1.csv'\n",
    "caminho_agressivo = 'data/agressivo/agressivo_1.csv'\n",
    "\n",
    "df_suave = pd.read_csv(caminho_suave, sep = ';', decimal = ',', skiprows = 1)\n",
    "df_normal = pd.read_csv(caminho_normal, sep = ';', decimal = ',', skiprows = 1)\n",
    "df_agressivo = pd.read_csv(caminho_agressivo, sep = ';', decimal = ',', skiprows = 1)\n",
    "\n",
    "#Gráfico com duas subtramas\n",
    "fig, ax = plt.subplots(3, 1, figsize=(15, 10), sharex=True)\n",
    "fig.suptitle('Comparação de Aceleração (Magnitude) entre Percursos', fontsize=16)\n",
    "\n",
    "# Calcula a magnitude da aceleração para cada percurso\n",
    "df_suave['acel_magnitude'] = np.sqrt(df_suave['ax']**2 + df_suave['ay']**2)\n",
    "df_normal['acel_magnitude'] = np.sqrt(df_normal['ax']**2 + df_normal['ay']**2)\n",
    "df_agressivo['acel_magnitude'] = np.sqrt(df_agressivo['ax']**2 + df_agressivo['ay']**2)\n",
    "\n",
    "#Plot do percurso suave\n",
    "ax[0].plot(df_suave['time'], df_suave['acel_magnitude'], color='green')\n",
    "ax[0].set_title('Percurso Suave')\n",
    "ax[0].set_ylabel('Aceleração (m/s^2)')\n",
    "ax[0].grid(True)\n",
    "\n",
    "#Plot do percurso normal\n",
    "ax[1].plot(df_normal['time'], df_normal['acel_magnitude'], color='orange')\n",
    "ax[1].set_title('Percurso Normal')\n",
    "ax[1].set_ylabel('Aceleração (m/s^2)')\n",
    "ax[1].grid(True)\n",
    "\n",
    "#Plot do percurso aggressivo\n",
    "ax[2].plot(df_agressivo['time'], df_agressivo['acel_magnitude'], color='red')\n",
    "ax[2].set_title('Percurso Agressivo')\n",
    "ax[2].set_xlabel('Tempo (s)')\n",
    "ax[2].set_ylabel('Aceleração (m/s^2)')\n",
    "ax[2].grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Célula 2.2: Visualização Comparativa Giroscópio\n",
    "\n",
    "caminho_suave = 'data/suave/suave_1.csv'\n",
    "caminho_normal = 'data/normal/normal_1.csv'\n",
    "caminho_agressivo = 'data/agressivo/agressivo_1.csv'\n",
    "\n",
    "df_suave = pd.read_csv(caminho_suave, sep = ';', decimal = ',', skiprows = 1)\n",
    "df_normal = pd.read_csv(caminho_normal, sep = ';', decimal = ',', skiprows = 1)\n",
    "df_agressivo = pd.read_csv(caminho_agressivo, sep = ';', decimal = ',', skiprows = 1)\n",
    "\n",
    "#Gráfico com três subtramas\n",
    "fig, ax = plt.subplots(3, 1, figsize=(15, 12), sharex=True)\n",
    "\n",
    "fig.suptitle('Comparação de Giroscópio (Intensidade das Curvas) entre Percursos', fontsize=16)\n",
    "\n",
    "# Plot do percurso suave\n",
    "ax[0].plot(df_suave['time'], df_suave['wz'].abs(), color='green')\n",
    "ax[0].set_title('Percurso Suave')\n",
    "ax[0].set_ylabel('Veloc. Angular |wz| (rad/s)')\n",
    "ax[0].grid(True)\n",
    "\n",
    "# Plot do percurso normal\n",
    "ax[1].plot(df_normal['time'], df_normal['wz'].abs(), color='orange')\n",
    "ax[1].set_title('Percurso Normal')\n",
    "ax[1].set_ylabel('Veloc. Angular |wz| (rad/s)')\n",
    "ax[1].grid(True)\n",
    "\n",
    "# Plot do percurso aggressivo\n",
    "ax[2].plot(df_agressivo['time'], df_agressivo['wz'].abs(), color='red')\n",
    "ax[2].set_title('Percurso Agressivo')\n",
    "ax[2].set_xlabel('Tempo (s)')\n",
    "ax[2].set_ylabel('Veloc. Angular |wz| (rad/s)')\n",
    "ax[2].grid(True)\n",
    "\n",
    "#Evita sobreposição dos gráficos\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee966d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Célula 3: Função de Extração de Características \n",
    "\n",
    "def extrair_caracteristicas(df_percurso):\n",
    "    \n",
    "    #Recebe um DataFrame de um único percurso e retorna um dicionário de características\n",
    "    #Usa os nomes de coluna 'ax', 'ay', 'wz' do arquivo.\n",
    "\n",
    "    caracteristicas = {}\n",
    "    \n",
    "    #Colunas de aceleração e giroscópio\n",
    "    acel_cols = ['ax', 'ay']\n",
    "    giro_cols = ['wz']\n",
    "\n",
    "    #Calcula a magnitude da aceleração, ignorando possíveis valores nulos\n",
    "    df_percurso['acel_magnitude'] = np.sqrt(df_percurso[acel_cols[0]]**2 + df_percurso[acel_cols[1]]**2).dropna()\n",
    "\n",
    "    #Características da Aceleração\n",
    "    caracteristicas['acel_std'] = df_percurso['acel_magnitude'].std()\n",
    "    caracteristicas['acel_max'] = df_percurso['acel_magnitude'].max()\n",
    "    caracteristicas['acel_q95'] = df_percurso['acel_magnitude'].quantile(0.95)\n",
    "\n",
    "    #Características do Giroscópio\n",
    "    caracteristicas['giro_std'] = df_percurso[giro_cols[0]].abs().std()\n",
    "    caracteristicas['giro_max'] = df_percurso[giro_cols[0]].abs().max()\n",
    "    caracteristicas['giro_q95'] = df_percurso[giro_cols[0]].abs().quantile(0.95)\n",
    "\n",
    "    return caracteristicas\n",
    "\n",
    "print(\"Função definida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c88d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Célula 4: Construção do Dataset de Características\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "categorias = ['agressivo', 'normal', 'suave']\n",
    "lista_de_percursos = []\n",
    "colunas_necessarias = ['ax', 'ay', 'wz']\n",
    "\n",
    "print(\"Processando arquivos...\")\n",
    "\n",
    "for categoria in categorias:\n",
    "    pasta_categoria = os.path.join(DATA_DIR, categoria)\n",
    "    \n",
    "    #Verifica se a pasta da categoria existe\n",
    "    if not os.path.exists(pasta_categoria):\n",
    "        print(f\"AVISO: Pasta da categoria '{categoria}' não encontrada. Pulando.\")\n",
    "        continue\n",
    "        \n",
    "    for nome_arquivo in os.listdir(pasta_categoria):\n",
    "        if nome_arquivo.endswith('.csv'):\n",
    "            caminho_completo = os.path.join(pasta_categoria, nome_arquivo)\n",
    "            \n",
    "            try:\n",
    "                df_temp = pd.read_csv(\n",
    "                    caminho_completo, \n",
    "                    sep=';', \n",
    "                    decimal=',', \n",
    "                    skiprows=1,\n",
    "                    on_bad_lines='skip' #Ignora linhas mal formatadas\n",
    "                )\n",
    "                \n",
    "                #Verifica se o arquivo tem as colunas necessárias\n",
    "                if all(col in df_temp.columns for col in colunas_necessarias):\n",
    "                    #Caso sim, extrai as características\n",
    "                    features = extrair_caracteristicas(df_temp)\n",
    "                    features['label'] = categoria    #Rotula\n",
    "                    lista_de_percursos.append(features)\n",
    "                else:\n",
    "                    #Caso não tenha, avisa e pula o arquivo\n",
    "                    print(f\"AVISO: Arquivo {nome_arquivo} pulado (colunas {colunas_necessarias} não encontradas).\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                #Se der qualquer outro erro ao ler o arquivo, avisa e pula\n",
    "                print(f\"ERRO ao processar o arquivo {nome_arquivo}: {e}\")\n",
    "\n",
    "#Cria o dataframe principal com todos os dados processados\n",
    "dataset = pd.DataFrame(lista_de_percursos)\n",
    "\n",
    "print(\"\\nDataset de características criado com sucesso!\")\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b709b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Célula 5: Geração de Dados Sintéticos (Data Augmentation)\n",
    "\n",
    "dataset_original = dataset.copy()\n",
    "print(f\"Tamanho do dataset original: {dataset_original.shape[0]} amostras.\")\n",
    "\n",
    "lista_dados_sinteticos = []\n",
    "\n",
    "#Parâmetros de geração\n",
    "n_filhos_por_amostra = 999    #Filhos sintéticos a serem criados para cada amostra original\n",
    "noise_level = 0.15         #Nível de ruído (0.15 = 15% de variação)\n",
    "\n",
    "for i in range(n_filhos_por_amostra):\n",
    "    #Itera sobre cada amostra original\n",
    "    for index, amostra_original in dataset_original.iterrows():\n",
    "        nova_amostra_sintetica = {}\n",
    "        features_originais = amostra_original.drop('label')\n",
    "        \n",
    "        #Adiciona ruído a cada característica\n",
    "        for feature_name, value in features_originais.items():\n",
    "            #Gera um ruído gaussiano\n",
    "            #O ruído é proporcional ao valor da característica (ex: 10% do valor)\n",
    "            #Adicionou-se 1e-6 para evitar erros se o valor for 0\n",
    "            ruido = np.random.normal(0, noise_level * abs(value) + 1e-6)\n",
    "            nova_amostra_sintetica[feature_name] = value + ruido\n",
    "        \n",
    "        # Adiciona o rótulo original\n",
    "        nova_amostra_sintetica['label'] = amostra_original['label']\n",
    "        \n",
    "        #Adiciona a nova amostra sintética à lista\n",
    "        lista_dados_sinteticos.append(nova_amostra_sintetica)\n",
    "\n",
    "#Cria um DataFrame com os dados sintéticos\n",
    "dataset_sintetico = pd.DataFrame(lista_dados_sinteticos)\n",
    "\n",
    "#Combina o dataset original com o sintético, mantendo os originais\n",
    "dataset = pd.concat([dataset_original, dataset_sintetico], ignore_index=True)\n",
    "\n",
    "print(f\"Tamanho do novo dataset (Original + Sintético): {dataset.shape[0]} amostras.\")\n",
    "\n",
    "#Visualizando nova distribuição de classes\n",
    "print(\"\\nNova distribuição de classes:\")\n",
    "print(dataset['label'].value_counts())\n",
    "\n",
    "#Observando os clusters de dados criados\n",
    "sns.scatterplot(data=dataset, x='acel_std', y='giro_max', hue='label', s=20, alpha=0.5)\n",
    "plt.title(\"Visualização dos Dados Aumentados\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ded7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Célula 6: Treinamento e Avaliação do Modelo\n",
    "\n",
    "print(\"Iniciando Treinamento e Avaliação do Modelo...\")\n",
    "print(f\"Total de amostras no dataset: {dataset.shape[0]}\")\n",
    "print(\"\\nAmostras por classe:\")\n",
    "print(dataset['label'].value_counts())\n",
    "\n",
    "#Verifica se o dataset não está vazio\n",
    "if dataset.empty:\n",
    "    print(\"ERRO: Dataset vazio. Verifique a pasta 'data'.\")\n",
    "else:\n",
    "    #Separando as características (X) dos rótulos (y)\n",
    "    X = dataset.drop('label', axis=1)\n",
    "    y = dataset['label']\n",
    "\n",
    "    #Dividindo os dados em treino e teste, test_size=0.25 significa que 25% dos dados vão para teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "    #Criando e treinando o modelo\n",
    "    modelo = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    #Fazendo previsões nos dados de teste\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    #Avaliando os resultados\n",
    "    acuracia = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Acurácia do modelo: {acuracia * 100:.2f}%\\n\")\n",
    "\n",
    "    print(\"Relatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=categorias))\n",
    "\n",
    "    #Plotando a Matriz de Confusão\n",
    "    print(\"Matriz de Confusão:\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ConfusionMatrixDisplay.from_estimator(modelo, X_test, y_test, display_labels=categorias, cmap='Blues', ax=ax)\n",
    "    plt.title('Matriz de Confusão')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
